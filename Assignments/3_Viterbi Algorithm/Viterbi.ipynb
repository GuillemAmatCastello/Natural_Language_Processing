{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3: Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student:** Guillem Amat (ga98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "import nltk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\guill\\Desktop\\Current Semester\\Natural Language Processing\\Homeworks\\Homework_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download packages if not available\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_tagging = nltk.corpus.brown.tagged_sents(tagset='universal')[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Creating Matrixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Initial tag-tag and tag-word lists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a (tag_{i}, tag_{i+1}) list of tuples for every sentence in the positional_tagging corpus\n",
    "tag_tag = [(tag[1], sentence[i+1][1]) for sentence in positional_tagging\n",
    "           for i, tag in enumerate(sentence[:-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a (tag_{i}, word_{i}) list of tuples for every sentence in the positional_tagging corpus: Extracting tuples\n",
    "word_tag = [word for sentence in positional_tagging for word in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transition Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up components to create Transition Matrix\n",
    "tag_vocabulary = set([tag[0] for tag in tag_tag])\n",
    "tag_dictionary = {tag: i for i, tag in enumerate(list(tag_vocabulary))}\n",
    "transition_matrix = np.zeros((len(tag_vocabulary), len(tag_vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populating the transition_matrix\n",
    "for tag in tag_tag:\n",
    "    tag_i  = tag_dictionary[tag[0]]\n",
    "    tag_i1 = tag_dictionary[tag[1]]\n",
    "    transition_matrix[tag_i, tag_i1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing & converthing tag counts to probabilities\n",
    "alpha = 0.01\n",
    "V_tag  = len(tag_vocabulary)\n",
    "d_tag  = (np.sum(transition_matrix, axis=1) + alpha*V_tag)[:, None] # We need to use [:, None] to make column division explicit\n",
    "transition_matrix = (transition_matrix+alpha)/d_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONJ</th>\n",
       "      <th>PRT</th>\n",
       "      <th>X</th>\n",
       "      <th>NUM</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>PRON</th>\n",
       "      <th>ADP</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>.</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>DET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CONJ   PRT     X   NUM   ADJ  PRON   ADP  NOUN     .   ADV  VERB   DET\n",
       "CONJ  0.00  0.02  0.00  0.02  0.12  0.05  0.07  0.29  0.02  0.09  0.16  0.16\n",
       "PRT   0.01  0.01  0.00  0.01  0.02  0.00  0.09  0.04  0.05  0.03  0.66  0.08\n",
       "X     0.02  0.00  0.46  0.00  0.00  0.00  0.07  0.11  0.26  0.01  0.05  0.00\n",
       "NUM   0.03  0.01  0.00  0.02  0.07  0.01  0.14  0.38  0.25  0.03  0.04  0.01\n",
       "ADJ   0.03  0.02  0.00  0.01  0.06  0.00  0.08  0.67  0.09  0.01  0.02  0.01\n",
       "PRON  0.01  0.02  0.00  0.00  0.01  0.01  0.05  0.01  0.08  0.06  0.73  0.01\n",
       "ADP   0.00  0.01  0.00  0.04  0.08  0.05  0.02  0.29  0.01  0.01  0.04  0.44\n",
       "NOUN  0.05  0.02  0.00  0.01  0.02  0.02  0.23  0.21  0.26  0.02  0.14  0.01\n",
       ".     0.09  0.02  0.00  0.02  0.05  0.06  0.11  0.18  0.14  0.06  0.13  0.12\n",
       "ADV   0.01  0.03  0.00  0.02  0.15  0.04  0.14  0.04  0.14  0.10  0.26  0.08\n",
       "VERB  0.01  0.06  0.00  0.01  0.06  0.04  0.17  0.11  0.07  0.10  0.19  0.18\n",
       "DET   0.00  0.00  0.00  0.01  0.25  0.01  0.01  0.62  0.01  0.02  0.06  0.01"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Transition Matrix\n",
    "df_tm = pd.DataFrame(transition_matrix, columns = tag_dictionary, index = tag_dictionary); df_tm.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up components to create Observation Matrix\n",
    "word_vocabulary    = set([word[0] for word in word_tag])\n",
    "word_dictionary    = {word: i for i, word in enumerate(list(word_vocabulary))}\n",
    "observation_matrix = np.zeros((len(tag_vocabulary), len(word_vocabulary))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wt in word_tag:\n",
    "    tag  = tag_dictionary[wt[1]] # Recycling this dictionary from the Transition Matrix\n",
    "    word = word_dictionary[wt[0]]\n",
    "    observation_matrix[tag, word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing & converting word-tag counts to probabilities\n",
    "alpha = 0.01\n",
    "V_word   = len(word_vocabulary)\n",
    "d_word   = (np.sum(observation_matrix, axis=1) + alpha*V_word)[:, None] # We need to use [:, None] to make column division explicit\n",
    "o_m = (observation_matrix + alpha)/d_word "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOV Methods for Observation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative approach by setting all tags to have equal probability\n",
    "# observation_matrix = np.append(o_m, np.ones(len(tag_vocabulary),).reshape(-1,1), axis = 1)\n",
    "#word_dictionary['OOV'] = observation_matrix.shape[1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding OOV observation to matrix\n",
    "observation_matrix = np.append(o_m, d_word/np.sum(d_word), axis=1) #np.append(o_m, np.ones(len(tag_vocabulary),).reshape(-1,1), axis = 1)\n",
    "word_dictionary['OOV'] = observation_matrix.shape[1]-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explained</th>\n",
       "      <th>black-bearded</th>\n",
       "      <th>poised</th>\n",
       "      <th>undertaken</th>\n",
       "      <th>OOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>1.459240e-06</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.459240e-06</td>\n",
       "      <td>1.459240e-06</td>\n",
       "      <td>0.030787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>1.884702e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.884702e-06</td>\n",
       "      <td>1.884702e-06</td>\n",
       "      <td>0.023837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>2.045492e-05</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>2.045492e-05</td>\n",
       "      <td>2.045492e-05</td>\n",
       "      <td>0.002196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>2.656833e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.656833e-06</td>\n",
       "      <td>2.656833e-06</td>\n",
       "      <td>0.016910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>6.002444e-07</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>6.002444e-07</td>\n",
       "      <td>6.002444e-07</td>\n",
       "      <td>0.074846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         explained  black-bearded        poised    undertaken       OOV\n",
       "CONJ  1.459240e-06       0.000001  1.459240e-06  1.459240e-06  0.030787\n",
       "PRT   1.884702e-06       0.000002  1.884702e-06  1.884702e-06  0.023837\n",
       "X     2.045492e-05       0.000020  2.045492e-05  2.045492e-05  0.002196\n",
       "NUM   2.656833e-06       0.000003  2.656833e-06  2.656833e-06  0.016910\n",
       "ADJ   6.002444e-07       0.000061  6.002444e-07  6.002444e-07  0.074846"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Transition Matrix\n",
    "df_om = pd.DataFrame(observation_matrix, columns = word_dictionary, index = tag_dictionary)\n",
    "df_om.iloc[:5, -5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial State Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not happy with this... very convoluted, need to improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to \n",
    "first_tag = [sentence[0][1] for sentence in positional_tagging]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of times each positional tag appears in the corpus\n",
    "initial_state = {}\n",
    "\n",
    "for tag in first_tag:\n",
    "    initial_state[tag] = initial_state.get(tag, 0) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the total amount of counts times the total count\n",
    "count = sum(initial_state.values())\n",
    "\n",
    "for k, v in initial_state.items():\n",
    "    initial_state[k] = v/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an array that will hold our dictionary values in the order of the transition matrix\n",
    "tag_list = [None] * len(tag_dictionary.items())\n",
    "\n",
    "for k, v in initial_state.items():\n",
    "    tag_list[tag_dictionary[k]] = v\n",
    "    pass\n",
    "    \n",
    "tag_array = np.array(tag_list).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Implementing Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(observations: List[str], pi: np.array, A: np.array, B: np.array) -> List[Tuple[str, str]]:\n",
    "    \n",
    "    #Setting up an initial matrix to hold our values and a list with the result\n",
    "    final_tag_list = []\n",
    "    viterbi_matrix = np.zeros((A.shape[0], len(observations))) \n",
    "    \n",
    "    #Calculating initial Viterbi matrix column\n",
    "    viterbi_matrix[:, 0] = np.log(pi * B[:, word_dictionary[observations[0]]])\n",
    "    \n",
    "    #Finding max value in the initial Viterbi column\n",
    "    max_tag = np.argmax(viterbi_matrix[:, 0])\n",
    "    final_tag_list.append(max_tag)\n",
    "    \n",
    "    #Iterating over every column\n",
    "    for index in range(1, len(observations)):\n",
    "        \n",
    "        if observations[index] in word_dictionary.keys():\n",
    "            viterbi_matrix[:, index] = np.log(A[max_tag, :] * B[:, word_dictionary[observations[index]]])\n",
    "        else:\n",
    "            viterbi_matrix[:, index] = np.log(A[max_tag, :] * B[:, word_dictionary['OOV']])\n",
    "        \n",
    "        #Finding max value in column iteration:= tag(i-1) for next iteration\n",
    "        max_tag = np.argmax(viterbi_matrix[:, index])\n",
    "        final_tag_list.append(max_tag)\n",
    "        pass\n",
    "    \n",
    "    #Producing final results by looking at indexes of words\n",
    "    inv = {val: key for key, val in tag_dictionary.items()}\n",
    "    result = [inv[tag] for tag in final_tag_list]\n",
    "\n",
    "    return list(zip(observations, result))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: Testing Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nltk.corpus.brown.tagged_sents(tagset='universal')[10150:10153]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [viterbi(extracted_sentence, tag_array, transition_matrix, observation_matrix)\n",
    "          for extracted_sentence in \n",
    "          [[word[0] for word in sentence] for sentence in test]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Those', 'DET'), 'DET'),\n",
       " (('coming', 'VERB'), 'VERB'),\n",
       " (('from', 'ADP'), 'ADP'),\n",
       " (('other', 'ADJ'), 'ADJ'),\n",
       " (('denominations', 'NOUN'), 'NOUN'),\n",
       " (('will', 'VERB'), 'VERB'),\n",
       " (('welcome', 'VERB'), 'VERB'),\n",
       " (('the', 'DET'), 'DET'),\n",
       " (('opportunity', 'NOUN'), 'NOUN'),\n",
       " (('to', 'ADP'), 'PRT'),\n",
       " (('become', 'VERB'), 'VERB'),\n",
       " (('informed', 'VERB'), 'VERB'),\n",
       " (('.', '.'), '.')]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(results[0], [tup[1] for tup in test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('The', 'DET'), 'DET'),\n",
       " (('preparatory', 'NOUN'), 'ADJ'),\n",
       " (('class', 'NOUN'), 'NOUN'),\n",
       " (('is', 'VERB'), 'VERB'),\n",
       " (('an', 'DET'), 'DET'),\n",
       " (('introductory', 'NOUN'), 'ADJ'),\n",
       " (('face-to-face', 'NOUN'), 'ADJ'),\n",
       " (('group', 'NOUN'), 'NOUN'),\n",
       " (('in', 'ADP'), 'ADP'),\n",
       " (('which', 'DET'), 'DET'),\n",
       " (('new', 'ADJ'), 'ADJ'),\n",
       " (('members', 'NOUN'), 'NOUN'),\n",
       " (('become', 'VERB'), 'VERB'),\n",
       " (('acquainted', 'VERB'), 'VERB'),\n",
       " (('with', 'ADP'), 'ADP'),\n",
       " (('one', 'NUM'), 'NUM'),\n",
       " (('another', 'DET'), 'DET'),\n",
       " (('.', '.'), '.')]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(results[1], [tup[1] for tup in test[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('It', 'PRON'), 'PRON'),\n",
       " (('provides', 'VERB'), 'VERB'),\n",
       " (('a', 'DET'), 'DET'),\n",
       " (('natural', 'ADJ'), 'ADJ'),\n",
       " (('transition', 'NOUN'), 'NOUN'),\n",
       " (('into', 'ADP'), 'ADP'),\n",
       " (('the', 'DET'), 'DET'),\n",
       " (('life', 'NOUN'), 'NOUN'),\n",
       " (('of', 'ADP'), 'ADP'),\n",
       " (('the', 'DET'), 'DET'),\n",
       " (('local', 'ADJ'), 'ADJ'),\n",
       " (('church', 'NOUN'), 'NOUN'),\n",
       " (('and', 'CONJ'), 'CONJ'),\n",
       " (('its', 'DET'), 'DET'),\n",
       " (('organizations', 'NOUN'), 'NOUN'),\n",
       " (('.', '.'), '.')]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(results[2], [tup[1] for tup in test[2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy Computation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class style:\n",
    "    start = '\\033[1m'\n",
    "    end = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = list(zip([tup[1] for sentence in results for tup in sentence], [tup[1] for sentence in test for tup in sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.sum([tup[0] == tup[1] for tup in res])/len(res)* 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAccuracy: \u001b[0m91.49%\n"
     ]
    }
   ],
   "source": [
    "print(style.start + 'Accuracy: ' + style.end + f'{accuracy.round(2)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
