{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2: Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ECE 684:** Natural Language Processing\n",
    "<br>\n",
    "**Name:** Guillem Amat Castello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Latent Dirichlet Allocation Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LDA Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA(vocabulary: list, beta: np.array, alpha: np.array, xi: int) -> np.array:\n",
    "    word_list = []\n",
    "    N = np.random.poisson(xi)\n",
    "    theta = np.random.dirichlet(alpha)\n",
    "    for word in range(N):\n",
    "        z = np.where(np.random.multinomial(1, theta) == 1)\n",
    "        word = np.where(np.random.multinomial(1, beta[z[0][0]])== 1)\n",
    "        word_list.append(vocabulary[word[0][0]])\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = ['bass', 'pike', 'deep', 'tuba', 'horn', 'catapult']\n",
    "beta = np.array([[0.4, 0.4, 0.2, 0.0, 0.0, 0.0],\n",
    "                 [0.0, 0.3, 0.1, 0.0, 0.3, 0.3],\n",
    "                 [0.3, 0.0, 0.2, 0.3, 0.2, 0.0]])\n",
    "alpha = np.array([1, 3, 8])\n",
    "xi = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = LDA(vocabulary, beta, alpha, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bass': 19, 'catapult': 1, 'deep': 15, 'horn': 14, 'pike': 2, 'tuba': 9}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(document, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Parameter Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating LDA Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = 100\n",
    "documents = [LDA(vocabulary, beta, alpha, xi) for i in range(documents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dictionary = corpora.Dictionary(documents)\n",
    "corpus = [word_dictionary.doc2bow(document) for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word = word_dictionary,\n",
    "                                            num_topics=3, \n",
    "                                            random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            passes=10,\n",
    "                                            alpha='auto',\n",
    "                                            per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracted Topics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.230*\"horn\" + 0.219*\"deep\" + 0.200*\"pike\" + 0.152*\"catapult\" + 0.118*\"tuba\" + 0.081*\"bass\"'), (1, '0.317*\"tuba\" + 0.254*\"deep\" + 0.198*\"horn\" + 0.184*\"bass\" + 0.028*\"catapult\" + 0.018*\"pike\"'), (2, '0.257*\"bass\" + 0.222*\"horn\" + 0.208*\"tuba\" + 0.134*\"deep\" + 0.104*\"pike\" + 0.075*\"catapult\"')]\n"
     ]
    }
   ],
   "source": [
    "print(lda_model.print_topics())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
