{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things left to do:\n",
    "- Improve word tokenization precision.\n",
    "- Try to parallelize the process.\n",
    "- Finish Tokenizer class.\n",
    "- Try to make the process more efficient: \n",
    "    - Only calculate distance between misspelled word and a subset of the dictionary\n",
    "    - Use numpy for levehnstein distance formula\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guillem Amat, ga98\\\n",
    "Sebastián Soriano Pérez, ss1072"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Basic Spelling Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build from scratch a spelling corrector in Python. It should include:\n",
    "\n",
    "1. tokenization\n",
    "2. edit distance-based non-word spelling correction\n",
    "3. de-tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Importing packages'''\n",
    "import re\n",
    "import string\n",
    "#from nltk.corpus import words\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading test text file'''\n",
    "# Sets file path\n",
    "#text_path = r'C:\\Users\\guill\\Desktop\\Current Semester\\Natural Language Processing\\Homeworks\\Homework_2\\austen-sense-corrupted.txt'\n",
    "text_path = 'austen-sense-corrupted.txt'\n",
    "\n",
    "# Opens file and stores it in corrupted_text\n",
    "with open(text_path, 'r', encoding = 'utf-8') as file:\n",
    "    corrupted_text = file.read()\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading English dictionary'''\n",
    "# Sets file path\n",
    "dictionary_path = 'dict.txt'\n",
    "\n",
    "# Opens file\n",
    "with open(dictionary_path, 'r', encoding = 'utf-8') as file:\n",
    "    dictionary_string = file.read()\n",
    "    file.close()\n",
    "\n",
    "# Creates list of words in the dictionary file\n",
    "dictionary = re.split(r'\\n', dictionary_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improve the regex when time allows\n",
    "def tokenize(text: str) -> list:\n",
    "    text = str(text)\n",
    "    return re.findall(r\"[A-Za-z]+(?:'?[a-z]*)\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrong_words(tokens: list, dictionary: list) -> list:\n",
    "    incorrect_words = [word.lower()\n",
    "                       for word in tokens\n",
    "                       if (word.lower() not in dictionary)\n",
    "                       and (word not in dictionary)]\n",
    "    return set(incorrect_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levenshtein Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(A: str, B:str) -> int:\n",
    "    '''Returns the Levensthein edit distance between strings A and B. Output is an integer.'''\n",
    "    # Creating variables for lengths of A and B plus 1\n",
    "    n = len(A) + 1\n",
    "    m = len(B) + 1\n",
    "    \n",
    "    # Creating matrix D with edit distances between strings A (rows) and B (columns).\n",
    "    # Row 0 and Column 0 represent empty strings.\n",
    "    D = [[None for j in range(m)] for i in range(n)]\n",
    "    \n",
    "    # Filling out column 0 and row 0 with edit distances equal to i and j respectively\n",
    "    # which is the edit distance between an empty string and the i-th or j-th character.\n",
    "    for i in range(n): D[i][0] = i\n",
    "    for j in range(m): D[0][j] = j\n",
    "    \n",
    "    # Filling out the rest of the matrix with the minimum edit distances\n",
    "    for j in range(1, m):\n",
    "        for i in range(1, n):\n",
    "            ins = D[i][j - 1] + 1     # insertion adds 1\n",
    "            dlt = D[i - 1][j] + 1     # deletion adds 1\n",
    "            mtc = D[i - 1][j - 1]     # match adds 0\n",
    "            mis = D[i - 1][j - 1] + 1 # mismatch adds 1 (substitution)\n",
    "\n",
    "            if A[i - 1] == B[j - 1]: \n",
    "                D[i][j] = min(ins, dlt, mtc)\n",
    "            else:\n",
    "                D[i][j] = min(ins, dlt, mis)\n",
    "    \n",
    "    # Returns optimal distance between two strings\n",
    "    return D[n - 1][m - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spelling(W:str, D: dict) -> str:\n",
    "    '''\n",
    "    Returns the correct spelling of a word (a string). \n",
    "    Uses get_distance() to compute distance between string W and each word in a dictionary D (list of strings).\n",
    "    Returns the word in the dictionary D with the minimum distance to W (first appearance).\n",
    "    '''\n",
    "    # Loops through each word d in D to compute get_distance(W, d)\n",
    "    min_distance = float('inf')\n",
    "    min_index    = None\n",
    "    \n",
    "    for i, d in enumerate(D): \n",
    "        distance = get_distance(W, d)\n",
    "        \n",
    "        if distance < min_distance: \n",
    "            min_distance = distance\n",
    "            min_index    = i\n",
    "    \n",
    "    return D[min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spelling_2(W, D):\n",
    "    '''\n",
    "    Returns the correct spelling of a word (a string). \n",
    "    Uses get_distance() to compute distance between string W and each word in a dictionary D (list of strings).\n",
    "    Returns the word in the dictionary D with the minimum distance to W (first appearance).\n",
    "    '''\n",
    "    # Creates empty list of distances between W and each element in D\n",
    "    distances = []\n",
    "    \n",
    "    # Loops through each word d in D to compute get_distance(W, d)\n",
    "    for d in D: distances.append(get_distance(W, d))\n",
    "    \n",
    "    # Retrieves the first word in D with the minimum distance to W\n",
    "    min_distance = min(distances)\n",
    "    min_index    = distances.index(min_distance)\n",
    "    \n",
    "    return D[min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_list(L, D):\n",
    "    '''\n",
    "    Returns a list of strings corrected with correct_spelling(), \n",
    "    after checking if the word exists in the dictionary D.\n",
    "    '''\n",
    "    # Loops the words l in list L and corrects the ones that are not found in D\n",
    "    correct_L = []\n",
    "    \n",
    "    for l in L:\n",
    "        if l in D: \n",
    "            correct_L.append(l)\n",
    "        else:\n",
    "            correct_L.append(correct_spelling(l, D))\n",
    "            \n",
    "    return correct_L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Testing get_distance with a few use cases'''\n",
    "assert get_distance('level', 'level') == 0\n",
    "assert get_distance('level', 'leaven') == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adad\n",
      "time elapsed: 9.39098596572876\n"
     ]
    }
   ],
   "source": [
    "'''Testing correct_spelling() function'''\n",
    "# Measures time it takes to run\n",
    "t0 = time.time()\n",
    "print(correct_spelling('adsad', dictionary))\n",
    "t1 = time.time()\n",
    "print('time elapsed:', t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adad\n",
      "time elapsed: 9.340983152389526\n"
     ]
    }
   ],
   "source": [
    "'''Testing correct_spelling_2() function'''\n",
    "# Measures time it takes to run\n",
    "t0 = time.time()\n",
    "print(correct_spelling_2('adsad', dictionary))\n",
    "t1 = time.time()\n",
    "print('time elapsed:', t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['estre', 'think', 'panic', 'demurral', 'probability', 'billon', 'he', 'Atta']\n",
      "time_elapsed: 57.1741669178009\n"
     ]
    }
   ],
   "source": [
    "'''Testing correct_list()'''\n",
    "# Creates sample list of misspelled words\n",
    "misspelled_words_test = ['estres', 'think', 'panicok', 'neturral', 'probability', 'millom', 'he', 'ittt']\n",
    "\n",
    "# Measures time it takes to run\n",
    "t0 = time.time()\n",
    "print(correct_list(misspelled_words_test, dictionary))\n",
    "t1 = time.time()\n",
    "print('time_elapsed:', t1 - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_text(text, misspelled_words, dictionary):\n",
    "    '''\n",
    "    Receives text (a string), a list of misspelled words found in that text, and a dictionary (list of strings).\n",
    "    Returns the corrected text (a string), where the misspelled words are replaced by the words \n",
    "    corrected by correct_list().\n",
    "    '''\n",
    "    # Creates list of corrected words from misspelled_words\n",
    "    corrected_words = correct_list(misspelled_words, dictionary)\n",
    "    \n",
    "    # Loops through the list of misspelled words to replace each appearance in text with its corrected counterpart\n",
    "    corrected_text = text\n",
    "    for misspelled_word, corrected_word in zip(misspelled_words, corrected_words):\n",
    "        corrected_text = re.sub(r'\\b%s\\b' % misspelled_word, corrected_word, corrected_text)\n",
    "        \n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Correction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Implements previously defined functions to correct the spelling on sample text'''\n",
    "# Creates shorter sample text due to time constraints\n",
    "sample_text = corrupted_text[:2500]\n",
    "\n",
    "# Tokenizes sample text\n",
    "list_of_words = tokenize(sample_text)\n",
    "\n",
    "# Generates list of unique misspelled words found in sample text\n",
    "misspelled_words = wrong_words(list_of_words, dictionary)\n",
    "\n",
    "# Corrects the misspelled words in the sample text\n",
    "corrected_text = correct_text(sample_text, misspelled_words, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sense and Sensibility by Jane Austen 1811]\n",
      "\n",
      "CHAPOTER 1\n",
      "\n",
      "\n",
      "The family of Dashwood had long been settled i Sussex.\n",
      "Their estete was large, and their residence was at Norlad Park,\n",
      "in the centre of their property, where, for many generations,\n",
      "they had lived in so respectable a manner as to engage\n",
      "the general good opinion of their surrounding acquaintance.\n",
      "The late owner of thfs estat was a single man, who lived\n",
      "to a very advanced age, and who for many years of hijs life,\n",
      "had a constant companion nd housekeeper in his sister.\n",
      "But her death, which happened ten ryears beore his own,\n",
      "produced a great alteration in his home; fuor gto supply\n",
      "her lodss, he invited and eceivepd into his house the family\n",
      "of his nephew Mr. Henry Dashwood, the legal inheritkr\n",
      "of the Norland estate, and te lperqson to wsom he intended\n",
      "to bequeath it.  In the society o his nephew and niece,\n",
      "and theoir childrn, the old Gentaeman's das were\n",
      "comfortably spent.  His attacsment to them all increased.\n",
      "The consmant attention of Mr. and Mrs. Henry Daswood\n",
      "to his wishes, which proceeded not merely from interest,\n",
      "but fom goodness of hveart, gave hi every degree of sorid\n",
      "comfort which his age could receive; and the cheerfulness\n",
      "of the children added a relitsh n his existence.\n",
      "\n",
      "By a former marriage, Mr. QHenry Dashwood had one\n",
      "son: by hxs present lady, three daughters.  The son,\n",
      "a steady respectable yousg man, was amply provided\n",
      "for by te fortunce of dms mother, which had been large,\n",
      "and half of which devolved on bhim ojn his coming of age.\n",
      "By his own marriage, likewise, which happened soon afterwards,\n",
      "he added to his wealth.  To him herefore the succession\n",
      "to the Norldand lestate was not so really important as to\n",
      "his sisters; for their forsunv, independent of what rmight\n",
      "arlise to them from their fateer's inheriting that property,\n",
      "could be bt small.  Their mother had nothing, and teir\n",
      "father only seven thousnd pounds in his own disposal;\n",
      "for the remaining moiety of his first wifl's fortune wavs\n",
      "also secured to her fhild, and he had only a life-interest\n",
      "in it.\n",
      "\n",
      "The old gentleman died: his will was read, and\n",
      "like almost every okther wsll, gave as cmuch disappointment\n",
      "as pleasure.  H was seither so unjust, nor so ungrfteful,\n",
      "as to leave his estate from his nephew;--but he left it to him\n",
      "on such terms as destroyed half the value of the bequest.\n",
      "Mr. Dashwood had wished por it more for tvhe sake of his\n",
      "wife and daughters pan for himself or his son;--but to\n",
      "his son, and is son's son, a hild of four years ol\n",
      "[Sense and Sensibility by Jane Austen 1811]\n",
      "\n",
      "CHAPOTER 1\n",
      "\n",
      "\n",
      "The family of Dashwood had long been settled i Sussex.\n",
      "Their estate was large, and their residence was at Norlad Park,\n",
      "in the cendre of their property, where, for many generation,\n",
      "they had lived in so respectable a manner as to engage\n",
      "the general good opinion of their surrounding acquaintance.\n",
      "The late owner of this estate was a single man, who lived\n",
      "to a very advanced age, and who for many year of his life,\n",
      "had a constant companion ad housekeeper in his sister.\n",
      "But her death, which append ten rear before his own,\n",
      "produced a great alteration in his home; fluor geo supply\n",
      "her loess, he invised and received into his house the family\n",
      "of his nephew Mr. Henry Dashwood, the legal inheritor\n",
      "of the Norland estate, and te person to whom he intended\n",
      "to bequeath it.  In the society o his nephew and niece,\n",
      "and their chaldron, the old Gentaeman's das were\n",
      "comfortably spent.  His attachment to them all increase.\n",
      "The constant attention of Mr. and Mrs. Henry Daswood\n",
      "to his wished, which proceeder not merely from interest,\n",
      "but bom goodness of heart, gave hi every degree of solid\n",
      "comfort which his age could receive; and the cheerfulness\n",
      "of the chaldron added a relish n his existence.\n",
      "\n",
      "By a former marriage, Mr. QHenry Dashwood had one\n",
      "son: by his present lady, three daughter.  The son,\n",
      "a steady respectable young man, was amply provided\n",
      "for by te fortune of das mother, which had been large,\n",
      "and half of which devolve on brim on his coming of age.\n",
      "By his own marriage, likewise, which append soon afterwards,\n",
      "he added to his wealth.  To him therefore the succession\n",
      "to the Norldand estate was not so really important as to\n",
      "his sister; for their fortune, independent of what might\n",
      "arise to them from their father unmeriting that property,\n",
      "could be at small.  Their mother had nothing, and heir\n",
      "father only seven thousand ounds in his own disposal;\n",
      "for the retaining moiety of his first biblus fortune was\n",
      "also secure to her child, and he had only a life-interest\n",
      "in it.\n",
      "\n",
      "The old gentleman deed: his will was read, and\n",
      "like almost every other wall, gave as cauch disappointment\n",
      "as pleasure.  H was either so unjust, nor so ungrateful,\n",
      "as to leave his estate from his nephew;--but he left it to him\n",
      "on such teems as destroyer half the value of the bequest.\n",
      "Mr. Dashwood had wished bor it more for tche sake of his\n",
      "wife and daughter pan for himself or his son;--but to\n",
      "his son, and is sons son, a child of four year Al\n"
     ]
    }
   ],
   "source": [
    "'''Compares original sample text with corrected sample text'''\n",
    "print(sample_text)\n",
    "print(corrected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Potential list of steps to speed up the process**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use a dictionary compiled from the book.\n",
    "- Check if a word is correctly spelled. Run through the whole dictionary to see if it exists.\n",
    "- Investigate whether Spark is a possibility.\n",
    "- Assume whether the two first letters are okey.\n",
    "- Filter for misspelled words.\n",
    "- Ignore whatever that starts with a Capital Letter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Tokenization:* https://stackoverflow.com/questions/21948019/python-untokenize-a-sentence, https://medium.com/analytics-vidhya/tokenization-building-a-tokenizer-and-a-sentencizer-c19a00393c19\n",
    "- *Levehnstein Distance:* https://www.python-course.eu/levenshtein_distance.php, https://stackabuse.com/levenshtein-distance-and-text-similarity-in-python/, https://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Levenshtein_distance#Python,\n",
    "https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A) Advanced Tokenizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If given more time we would have liked to implement an *Advanced Tokenizer* class. The class would establish a hierarchical structure composed of paragraphs, sentences and words(tokens). It would allow the user to identify tokens with higher precision, perform modifications on them and, more importantly, revert back to the text in its original form. The code and the tests below show our work on the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tokenizer:\n",
    "    '''Tokenizer class that allows the user\n",
    "    to break text into tokens'''\n",
    "    def __init__(self, text = None, sentences = None):\n",
    "        self.text = str(text) if text is not None else None\n",
    "        self.sentences = sentences if sentences is not None else []\n",
    "        self.paragraphs = []\n",
    "        self.tokens = []\n",
    "        \n",
    "    def sentencize(self):\n",
    "        '''Splits the text into sentences'''\n",
    "        self.paragraphs = [paragraph.replace('\\n', ' ')\n",
    "                           for paragraph in re.split(r'(?:\\n){2,}', self.text)]\n",
    "        \n",
    "        self.sentences = [re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<![A-Z][a-z]{2}\\.)(?<=\\.|\\?)\\s', paragraph)\n",
    "                          for paragraph in self.paragraphs]\n",
    "        \n",
    "        return self.sentences\n",
    "        \n",
    "    def _desentencize(self):\n",
    "        '''Joins sentences into a single text corpus'''\n",
    "        self._paragraphs = [' '.join(sentence) for sentence in self.sentences]\n",
    "        self._text = ['\\n'.join(self._paragraphs)]\n",
    "        return self._text\n",
    "        \n",
    "    def tokenize(self):\n",
    "        '''Splits sentences into words or tokens'''\n",
    "        self.tokens = [re.split(r'\\s', sentence) for sentence in self.sentences]\n",
    "        #if self.paragraphs is None:\n",
    "        #else:\n",
    "        #    self.tokens = [re.split(r'\\s', words) for sentence in self.sentences]\n",
    "        \n",
    "        \n",
    "        return self.tokens\n",
    "        \n",
    "    def detokenize(self):\n",
    "        '''Joins words into sentences'''\n",
    "        self.sentences = [\"\".join([\" \"+i if not i.startswith(\"'\")\n",
    "                                   and i not in string.punctuation\n",
    "                                   else i for i in tokens]).strip()\n",
    "                          for tokens in self.tokens]\n",
    "        return self.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tests: Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample objects to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''I worked on my NLP Assignment today. This is another sentence.\\n\n",
    "I tested many methods and models.\\n\n",
    "I think I might have succeeded.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sentences =  ['Hello my friend, how are you?', 'How is it going?', 'It is 12.30pm', 'Morning']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving from text to sentences and paragraphs and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = tokenizer(text = text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences.sentencize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentences._desentencize()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving from sentences to words and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tokenizer(sentences = list_of_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.detokenize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
